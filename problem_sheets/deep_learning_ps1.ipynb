{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **C6.5 Theories of Deep Learning**\n",
        "\n",
        "Problem Sheet 1 - *Luca Michaelides*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2Ea0Ks-g87k"
      },
      "source": [
        "#### 1. Training Networks\n",
        "\n",
        "In this section we will build two Neural Networks, one from scratch, and one based on the high-level functions provided by Tensorflow.\n",
        "\n",
        "We will build a net from scratch to solve the XOR problem, and to do this we will rely on the backpropagation formulae that you have derived in the problem sheet.\n",
        "\n",
        "We will also build a network with Tensorflow to introduce you to their API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptfXqkaZiLMM"
      },
      "source": [
        "#### 1(b) XOR problem - NN from Scratch\n",
        "\n",
        "In this problem we have four possible inputs with two possible outcomes;\n",
        "\n",
        "\n",
        "> $x_1 = 0, x_2 = 0 \\Rightarrow XOR(x_1,x_2)=0$\n",
        "\n",
        "> $x_1 = 0, x_2 = 1 \\Rightarrow XOR(x_1,x_2)=1$\n",
        "\n",
        "> $x_1 = 1, x_2 = 0 \\Rightarrow XOR(x_1,x_2)=1$\n",
        "\n",
        "> $x_1 = 1, x_2 = 1 \\Rightarrow XOR(x_1,x_2)=0$\n",
        "\n",
        "In the problem sheet you may have noticed that a two layer NN  could solve this problem exactly. Here we will see that on a 2-layer net with Sigmoid activation functions, with a random intialisation and the mean square loss, back-prop is able to converge to a pseudo-optimal solution. We will then consider a visualisation of how the neural network divides the input space as a classifier.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz4eQDGFI7b0"
      },
      "source": [
        "**Exercise** The class for the NeuralNet is already defined except for the backpropagation function, which you have to complete.\n",
        "\n",
        "Note: Once you have implemented backprop, if you get poor performance, try running the cell again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "ZBiFs8xZGNlM",
        "outputId": "b8937e10-5881-4eff-f880-b68b62c8b732"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (1307497658.py, line 45)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31md_weights2 +=\u001b[39m\n                  ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1.0/(1+ np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1.0 - x)\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, x, y):\n",
        "        dimension = 2\n",
        "        self.input        = x\n",
        "        self.weights1     = np.random.rand(dimension, x.shape[1])      #np.array([[-1,1],[1,-1]], dtype=np.float)\n",
        "        self.weights2     = np.random.rand(1,dimension)\n",
        "        self.bias1        = np.random.rand(dimension,1)      #0.5*np.ones((dimension,1))\n",
        "        self.bias2        = np.random.rand(1,1)\n",
        "        self.y            = y\n",
        "        self.output       = np.zeros(self.y.shape)\n",
        "        self.activation   = sigmoid\n",
        "        self.d_activation = sigmoid_derivative\n",
        "\n",
        "    def feedforward(self,x):\n",
        "        self.x = np.expand_dims(x,axis =1)\n",
        "        self.layer1 = self.activation(self.weights1 @  self.x + self.bias1)\n",
        "        self.output = self.activation(self.weights2 @ self.layer1 + self.bias2)\n",
        "\n",
        "    def call(self,x):\n",
        "        x = np.expand_dims(x,axis =1)\n",
        "        layer1 = self.activation(self.weights1 @  x + self.bias1)\n",
        "        output = self.activation(self.weights2 @ layer1 + self.bias2)\n",
        "        return output\n",
        "\n",
        "    def backprop(self):\n",
        "        # application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n",
        "        d_weights1 = np.zeros(self.weights1.shape)\n",
        "        d_weights2 = np.zeros(self.weights2.shape)\n",
        "        d_bias1    = np.zeros(self.bias1.shape)\n",
        "        d_bias2    = np.zeros(self.bias2.shape)\n",
        "\n",
        "        for j in range(4):\n",
        "          # compute gradient per each input image\n",
        "          single_input = self.input[j]\n",
        "          self.feedforward(single_input)\n",
        "\n",
        "          d_weights2 += \n",
        "          d_bias2    +=\n",
        "          d_weights1 +=\n",
        "          d_bias1    +=\n",
        "\n",
        "        self.weights1 -= d_weights1\n",
        "        self.weights2 -= d_weights2\n",
        "        self.bias1    -= d_bias1\n",
        "        self.bias2    -= d_bias2\n",
        "\n",
        "X = np.array([[0,0],\n",
        "              [0,1],\n",
        "              [1,0],\n",
        "              [1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "nn = NeuralNetwork(X,y)\n",
        "\n",
        "for i in range(10000):\n",
        "    nn.backprop()\n",
        "for j in range(4):\n",
        "    nn.feedforward(X[j])\n",
        "    print('Prediction:\\n', nn.x, ' --->' , nn.output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ncvIv2vepg6"
      },
      "source": [
        "Now we will plot how the domain has been split. In the left figure we will see the outputs of the NN, while on the right we visualise the classification of these outputs i.e. any value above 0.5 identifies class 1, 0 otherwise, which shows us the decision boundary of the classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jI1Tv1mAeyl9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mu = np.linspace(0,1,100)\n",
        "gamma = np.linspace(0,1,100)\n",
        "\n",
        "# filling the heatmap, value by value\n",
        "fun_map = np.empty((mu.size, gamma.size))\n",
        "for i in range(mu.size):\n",
        "    for j in range(gamma.size):\n",
        "        net_val = nn.call([mu[i], gamma[j]])\n",
        "        if net_val>0.5:\n",
        "          fun_map[i,j] = 1\n",
        "        else:\n",
        "          fun_map[i,j] = 0\n",
        "\n",
        "fun_map_2 = np.empty((mu.size, gamma.size))\n",
        "for i in range(mu.size):\n",
        "    for j in range(gamma.size):\n",
        "        fun_map_2[i,j] = nn.call([mu[i], gamma[j]])\n",
        "\n",
        "fig = plt.figure()\n",
        "s = fig.add_subplot(1, 2, 1, xlabel='$x$', ylabel='$y$')\n",
        "im = s.imshow(\n",
        "    fun_map_2,\n",
        "    extent=(gamma[0], gamma[-1], mu[0], mu[-1]),\n",
        "    origin='lower')\n",
        "fig.colorbar(im)\n",
        "s = fig.add_subplot(1, 2, 2, xlabel='$x$', ylabel='$y$')\n",
        "im = s.imshow(\n",
        "    fun_map,\n",
        "    extent=(gamma[0], gamma[-1], mu[0], mu[-1]),\n",
        "    origin='lower')\n",
        "fig.colorbar(im)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzDVeZloHFwy"
      },
      "source": [
        "N.B. The transition fase with the sigmoid activation function is sharp, and so the NN more-or-less splits the domain into piecwise constant regions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIrwTlPU7iVe"
      },
      "source": [
        "#### 1(c) Training MNIST\n",
        "\n",
        "First, we have to upload the dataset; keras, an interface for tensorflow, allows us to do this with a one line command. We then can use the Sequence model class from TF to add different layers to our network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "MJpPyFJyDXC9",
        "outputId": "89521ee9-e38e-4913-c141-19456ce264a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels)= mnist.load_data()\n",
        "\n",
        "print(train_images.shape) # Check if images are loaded correctly\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9c213Z3MfrD"
      },
      "source": [
        "**Exercise** You now have to generate a two layer network with hidden dimension of 128 via the sequential command in Tensorflow. This should allow you to achieve 92% accuracy with only15 epochs of training!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qO2O_0T7MiHb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "\n",
        "# Generate data\n",
        "x_train = train_images\n",
        "y_train = train_labels\n",
        "\n",
        "x_test = test_images\n",
        "y_test = test_labels\n",
        "\n",
        "# build the architecture with Sequential\n",
        "# ...\n",
        "\n",
        "# Compile the model, which involved shoows a loss function, an optimiser, and the performance metrics you want to track\n",
        "# ...\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVt3HV5hM_bJ"
      },
      "outputs": [],
      "source": [
        "# train the architecture\n",
        "#..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdgtcleFNDI9"
      },
      "outputs": [],
      "source": [
        "# test the performance\n",
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbdIpyUpNxec"
      },
      "source": [
        "#### 2. Expressivity\n",
        "\n",
        "The **$n$-ap problem** was shown to have an optimal solution with a particular construction of neural network. Do we find these coefficients/weights when training a network with that structure from randomly inittialised weights?\n",
        "\n",
        "#### 2(d) Train NN on n-ap problem\n",
        "\n",
        "Build the net in the case with $n=2^K, K=3$ and check if it converges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxwKrnWmPzrG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "# Generate data\n",
        "X = np.array([[0],\n",
        "                  [.125],\n",
        "                  [.25],\n",
        "                  [.375],\n",
        "                  [.5],\n",
        "                  [.625],\n",
        "                  [.75],\n",
        "                  [.875]])\n",
        "y = np.array([[0],[1],[0],[1],[0],[1],[0],[1]])\n",
        "x_train = X\n",
        "y_train = y\n",
        "\n",
        "# Build a model\n",
        "# ...\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "# ...\n",
        "\n",
        "scores = model.evaluate(X, y)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "ynew = model.predict_classes(x_train)\n",
        "for i in range(len(x_train)):\n",
        "\tprint(\"Y=%s, Predicted=%s\" % (y_train[i], ynew[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zVbcSsha9xQ"
      },
      "source": [
        "And now let's plot the modelled function\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5V40mAne235"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_model(nn,x,y):\n",
        "  xx = np.linspace(0,1,10000)\n",
        "  yy = nn.predict(xx)\n",
        "  fig = plt.figure()\n",
        "  plt.plot(xx,yy)\n",
        "  plt.plot(x,y, 'rx')\n",
        "\n",
        "plot_model(model, x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2k7mG-BaBPn"
      },
      "source": [
        "#### 2(e) Perturbed Solution of the n-ap problem\n",
        "\n",
        "Why is this optimum so hard to find? Let's implement the optimal function directly and see how a small perturbation to the parameters changes the function it computes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8lV3gR-aFNd"
      },
      "outputs": [],
      "source": [
        "# Fill in the weights and bias vactors given the optimal function to be composed, given in question 1b\n",
        "\n",
        "w1 =\n",
        "w2 =\n",
        "b1 ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2elCP_RaHrg"
      },
      "outputs": [],
      "source": [
        "def relu(x):\n",
        "  return np.maximum(x,0)\n",
        "\n",
        "class f():\n",
        "  def __init__(self, num_blocks, noise_stddev=0):\n",
        "    self.weights  = []\n",
        "    self.biases = []\n",
        "    for i in range(num_blocks):\n",
        "      w1_n = w1+ np.random.normal(scale = noise_stddev, size = w1.shape)\n",
        "      w2_n = w2+ np.random.normal(scale = noise_stddev, size = w2.shape)\n",
        "      b1_n = b1+ np.random.normal(scale = noise_stddev, size = b1.shape)\n",
        "      self.weights.append([w1_n,w2_n])\n",
        "      self.biases.append(b1_n)\n",
        "\n",
        "  def forward(self,x):\n",
        "    output = x\n",
        "    for i in range(len(self.weights)):\n",
        "      output = relu(self.weights[i][1] @ (relu(self.weights[i][0] @ output + self.biases[i])))\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBfBGCy5aRI3"
      },
      "outputs": [],
      "source": [
        "x = np.expand_dims(np.linspace(0,1,10000), 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PARdoS6CaT3C"
      },
      "outputs": [],
      "source": [
        "no_noise = f(6,0)\n",
        "noise = f(6,0.1)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(x[0,:], no_noise.forward(x).T, label = \"Without noise\")\n",
        "\n",
        "plt.plot(x[0,:], noise.forward(x).T, label = \"With noise\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRVwoXF8avNB"
      },
      "source": [
        "#### 2(f) Interatction Between Detph and Width\n",
        "\n",
        "Learning a piecewise smooth function from sample values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbyNydJZazTE",
        "outputId": "397ab38e-f65c-46ed-efa4-a29f0cb95358"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0822 - mse: 0.0822\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0384 - mse: 0.0384\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0063 - mse: 0.0063\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0040 - mse: 0.0040\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0036 - mse: 0.0036\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0033 - mse: 0.0033\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0026 - mse: 0.0026\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0033 - mse: 0.0033\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0024 - mse: 0.0024\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0026 - mse: 0.0026\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0029 - mse: 0.0029\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0021 - mse: 0.0021\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0022 - mse: 0.0022\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0021 - mse: 0.0021\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0026 - mse: 0.0026\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0022 - mse: 0.0022\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0022 - mse: 0.0022\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0017 - mse: 0.0017\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0025 - mse: 0.0025\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb5aacd890>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "train_samples=10000\n",
        "\n",
        "x_train=np.expand_dims(np.sort(np.random.uniform(0,1,train_samples)), 1)\n",
        "\n",
        "#generate samples of y=sin(x * pi) for x\\in[0,1) and y=x^2 for x\\in[1/2,1]\n",
        "def test_func(x):\n",
        "    return np.sin(x*np.pi)*(x<1/2) + x**2*(x>=1/2)\n",
        "\n",
        "y_train=test_func(x_train)\n",
        "\n",
        "#uncommenting the below shows the samples\n",
        "#plt.figure()\n",
        "#plt.plot(x_train,y_train)\n",
        "\n",
        "#we now train a network base on the samples (x_train,y_train) and evaluate it on x_test.\n",
        "\n",
        "#consider varying the network width and depth,\n",
        "#width and depth are controlled through the variables \"width\" and \"depths respectively\",\n",
        "\n",
        "width=10\n",
        "depth=10\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(width, input_dim=1, activation='relu'))\n",
        "\n",
        "for i in range(depth-2):\n",
        "  model.add(Dense(width, activation='relu'))\n",
        "\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer = 'adam',  metrics=['mse'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=32,verbose=1)\n",
        "\n",
        "# scores = model.evaluate(X, y)\n",
        "# print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "1-__gjJPa882",
        "outputId": "2a00bcdc-92c0-4097-9471-59406c065ebb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fbb5921b990>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "x_test=np.linspace(0,1,10000)\n",
        "y_test = test_func(x_test)\n",
        "\n",
        "x_test = np.expand_dims(x_test,  axis=1)\n",
        "y_test_estimate = model(x_test)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(x_test,y_test_estimate, label = \"fitted\")\n",
        "plt.plot(x_test, y_test, label = \"ground truth\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPP_7EuecVk-"
      },
      "source": [
        "Try and do something similar to the code above - but for a 2-d function\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
